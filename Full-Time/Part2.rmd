---
title: "Cyence Data Exercise"
author: "Yiming Gao"
date: "2/18/2018"
output:
  html_document:
    theme: readable
    toc: true
    toc_float: true
---
<style type="text/css">

body{ /* Normal  */
      font-size: 15px;
  }
</style>

# Part 2
## Exploratory Data Analysis & Feature Engineering
First I load some necessary libraries and define an evaluation function as well as a function to extract the best result from a caret object.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(data.table)
library(testthat)
library(gridExtra)
library(corrplot)
library(GGally)
library(ggplot2)
library(e1071)
library(dplyr)
library(readr)
library(caret)
library(MASS)
library(Rtsne)
library(nnet)
library(tidyverse)
library(anomalyDetection)
library(pROC)
library(mlbench)
library(mice)
library(Hmisc) # Imputation missing values with mean/ median/ mode

# extract the row with the best tuning parameters
get_best_result = function(caret_fit) {
  best_result = caret_fit$results[as.numeric(rownames(caret_fit$bestTune)), ]
  rownames(best_result) = NULL
  best_result
}

# Helper Functions
plotHist <- function(data_in, i) {
  data <- data.frame(x=data_in[[i]])
  p <- ggplot(data=data, aes(x=factor(x))) + stat_count() + xlab(colnames(data_in)[i]) + theme_light() + 
    theme(axis.text.x = element_text(angle = 90, hjust =1))
  return (p)
}

doPlots <- function(data_in, fun, ii, ncol=3) {
  pp <- list()
  for (i in ii) {
    p <- fun(data_in=data_in, i=i)
    pp <- c(pp, list(p))
  }
  do.call("grid.arrange", c(pp, ncol=ncol))
}

plotDen <- function(data_in, i){
  data <- data.frame(x=data_in[[i]])
  p <- ggplot(data= data) + geom_line(aes(x = x), stat = 'density', size = 1,alpha = 1.0) +
    xlab(paste0((colnames(data_in)[i]), '\n', 'Skewness: ',round(skewness(data_in[[i]], na.rm = TRUE), 2))) + theme_light() 
  return(p)
}

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

First of all, I would like to see which variables contain missing values:

```{r}
data = read.csv("data_perm_take_home.csv")
data = data[data$case_status == "Certified", ]
sapply(data, function(x) {sum(is.na(x))})
```

It seems that among `r nrow(data)` observations, `job_experience_num_months` has 16933 NAs, which indicates we might consider imputation in the future analysis because it's important intuitively. And also, our target variable `wage_offer` has some missing values and I will handle them later.

### Response Variable
Since there are different wage units with values "Year", "Month", "Week", and "Hour", I will make them consistent as the annual salary, by assuming working 52 weeks per year, 40 hours per week. There are also some missing values in `wage_unit`.

```{r}
table(data$wage_unit)
```

Since most of the `wage_unit` are "Hour" and "Year", I will ignore the other two. And calculate missing value if

- `wage_offer` < 10,000, then `wage_unit` = "Hour"
- `wage_offer` >= 10,000, then `wage_unit` = "Year"

From the density plot below, we find that most wage values fall around 75,000/ year. 

```{r, fig.align='center', message=FALSE, warning=FALSE}
data = data[data$case_status == "Certified", ]

data$wage = ifelse(data$wage_unit == "Year", data$wage_offer,
                   ifelse(data$wage_unit == "Month", data$wage_offer * 12, 
                          ifelse(data$wage_unit == "Week", data$wage_offer * 52, 
                                 data$wage_offer * 40 * 52)))
# Imputation of missing values
data$wage = ifelse(data$wage_unit %in% c("Year", "Month", "Week", "Day"), data$wage,
                   ifelse(data$wage_offer < 10000, data$wage_offer * 52 * 40, data$wage_offer))

ggplot(data, aes(wage)) +
  geom_density(color = "dodgerblue2", fill = "dodgerblue2", alpha = 0.5) + xlim(0, 200000)
```

### Predictor Variables
Here we want to predict `wage`, which I think will do nothing with case-related variables, because `wage` actually serves as a predict for `case_status`. 

Among the remained variables, I manally filtered some predictors that might be useful for predicting `wage`, including `employer_name`, `employer_num_employees`, `employer_yr_established`, `job_education`, `job_experience_num_month`, `job_state`, `job_level` and `employee_citizenship`. For simplicity, let's first explore part of the predictors that I think will be important for prediction.

**1. `employer_name`**

I plot 5 employers with most entries in the dataset, and set the remaining as "others".

```{r, echo=FALSE}
temp = as.data.frame(table(data$employer_name))
top5 = temp[order(-temp$Freq), ][1:5, ]
dt = data.frame(A = c(top5$Freq[1], top5$Freq[2], top5$Freq[3], top5$Freq[4], top5$Freq[5], nrow(data) - sum(top5$Freq)), B = c(as.vector(top5$Var1), "Others"))
myLabel = as.vector(dt$B) 
myLabel = paste(myLabel, " (", round(dt$A / sum(dt$A) * 100, 2), "%)", sep = "")  


p = ggplot(dt, aes(x = "", y = A, fill = B)) + 
  geom_bar(stat = "identity", width = 1) +    
  coord_polar(theta = "y") + 
  labs(x = "", y = "", title = "") + 
  theme(axis.ticks = element_blank()) + 
  theme(legend.title = element_blank(), legend.position = "top") + 
  scale_fill_discrete(breaks = dt$B, labels = myLabel) +
  theme(axis.text.x = element_blank()) 
p
```

**2. `employer_num_employees`**

Since there exists 1-1 mapping from `employee_name` to `employer_num_employees`, we could only consider one of them?

From the scatterplot below, we notice that the distribution is completely random with no pattern. So I won't use this variable in the future.

```{r, message=FALSE, warning=FALSE, fig.align="c"}
ggplot(data, aes(x = employer_num_employees, y = wage)) +
  geom_point(colour = "dodgerblue2", size = 1.5, alpha = 0.5) +
  ylim(0, 250000) + xlim(0, 500000)
```

**3. `employer_yr_established`**

This is a variable that uniquely corresponds to `employee_name`.

This is a variable that sounds useful at the beginning. Let's explore its relationship with our target variable `wage`. From the scatterplot below, we notice that the distribution is somewhat random with no pattern. I cannot tell if to keep it or not.

```{r, message=FALSE, warning=FALSE, fig.align="c"}
ggplot(data, aes(x = employer_yr_established, y = wage)) +
  geom_point(colour = "dodgerblue2", size = 1.5, alpha = 0.5) +
  ylim(0, 300000)
```

**4. `job_education`**

```{r}
table(data$job_education)
```

First we know that there're 7 unique values: Bachelor's, Doctorate, Master's, None, Other, Associate's and High School. The boxplot of mean wage by job education is shown below. We notice there seems to be little difference BS, MS and PhD, but do exist some difference among others.

Maybe we could consider categorizing BS, MS and PhD into one big class "BMD", and the rest remaining the same.

```{r, echo=FALSE, fig.align="c", message=FALSE, warning=FALSE}
plotdata = data
plotdata$job_education = factor(plotdata$job_education)
ggplot(plotdata, aes(x = job_education, y = wage)) +
  geom_boxplot(colour = "black", fill = "#56B4E9") +
  scale_x_discrete(name = "Job Education") +
  scale_y_continuous(name = "Mean Wage", breaks = seq(10000, 210000, 20000), limits = c(10000, 200000)) +
  ggtitle("Boxplot of Mean Wage by Job Education") +
  theme(axis.line.x = element_line(size = 0.5, colour = "black"),
        axis.line.y = element_line(size = 0.5, colour = "black"),
        axis.line = element_line(size=1, colour = "black"),
        panel.grid.major = element_line(colour = "#d3d3d3"),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank())
```

**5. `job_experience_num_months`**

***Missing Value Imputation:*** I think it should be a predictor with strong predictive power. However, there are many missing values in our dataset. I will use the simpliest Linear Regression to predict those missing values, using `job_state`, `job_education` and `wage`.

```{r}
dataLM = data
job_experience_num_monthsLM = lm(job_experience_num_months ~ job_state + wage + job_education, data = dataLM[!is.na(dataLM$job_experience_num_months), ])
dataLM$job_experience_num_monthsLM = predict(job_experience_num_monthsLM, dataLM)
```

Below is the histogram of the predicted values versus the shape of the known `job_experience_num_months`. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow = c(1, 2))
hist(dataLM$job_experience_num_months[!is.na(dataLM$job_experience_num_months)], main='Original data, non-missing', xlab='job_experience_num_months', col='green')
hist(dataLM$job_experience_num_monthsLM[is.na(dataLM$job_experience_num_months)], main= 'LM NA predictions', xlab='job_experience_num_months', col='orange', xlim = range(0: 200))
```

Then I replaced the NAs with predicted values in our raw dataset, and create similar scatterplot. There seems to be slight increasing trend so I will keep this for now.

```{r}
data[is.na(data$job_experience_num_months), ]$job_experience_num_months = dataLM$job_experience_num_monthsLM[is.na(data$job_experience_num_months)]
```

```{r, echo=FALSE, fig.align="c", message=FALSE, warning=FALSE}
ggplot(data, aes(x = job_experience_num_months, y = wage)) +
  geom_point(colour = "dodgerblue2", size = 1.5, alpha = 0.5) +
  ylim(0, 250000) + xlim(0,50)
```

**6. `job_state`**

I'm going to make a US map at a state level, with color of states representing the number of cases. 

`ggplot2` provides the `map_data()` function which contains the relevant map data. `plotdata` is the resulting dataset of merging US's states and the Frequency table by state derived from our dataset.

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(ggmap)
library(maps)
library(mapdata)
library(RColorBrewer)
```

```{r, fig.align="c", message=FALSE, warning=FALSE, include=FALSE}
states = map_data("state")
states$region = toupper(states$region)
temp1 = as.data.frame(table(data$job_state))
temp2 = temp1[order(-temp1$Freq), ]
plotdata = full_join(states, temp2, by = c("region" = "Var1"))
```

The Frequency in California and Texas is so great that makes it hard to discern differences between other areas. I will take the log-base-10 transformation of the frequency for this map.

```{r, echo=TRUE, fig.align="c", message=FALSE, warning=FALSE}
state_base = ggplot(data = plotdata, mapping = aes(x = long, y = lat, group = group)) + coord_fixed(1.3) + geom_polygon(color = "white", fill = "gray") 

state_base + 
  geom_polygon(data = plotdata, aes(fill = Freq), color = "white") +
  scale_fill_gradientn(colours = rev(terrain.colors(7)),
                       breaks = c(10, 100, 1000, 10000),
                       trans = "log10")
```

Because I think `job_state` is an important predictor for `wage`, I also calculate the average wage by state, then plot them on map. We can notice Wyoming and Arkansas have the highest average wage amount in our dataset.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
wage_state_avg = data %>% group_by(job_state) %>% summarise(wage_state_avg = mean(wage, na.rm = TRUE))
plotdata = full_join(states, wage_state_avg, by = c("region" = "job_state"))

# Plot state average wage
state_base + 
  geom_polygon(data = plotdata, aes(fill = wage_state_avg), color = "white") +
  scale_fill_gradientn(colours = rev(terrain.colors(9)),
                       breaks = c(10, 100, 1000, 10000),
                       trans = "log10")
```
```{r}
# Have a look at two states with highest average wages
head(wage_state_avg[order(-wage_state_avg$wage_state_avg),], 2)
```

**7. `job_level`**

I will use barplot to show the job level. We can see that most people have job level 2 in our data set.

```{r, fig.align="c", message=FALSE, warning=FALSE}
temp1 = as.data.frame(table(data$job_level))
temp2 = temp1[order(-temp1$Freq), ]
temp2$Var1 = as.factor(temp2$Var1)

ggplot(data = temp2, aes(x = Var1, y = Freq, color = Var1)) +
  geom_bar(stat = "identity", fill = "white") + 
  labs(x = 'How the job level is distributed?', fill = "Job Level") +
  geom_label(stat = "identity", aes(label = Freq)) +
  guides(color = guide_legend(title = "Job Level"))
```

Also, boxplot is a good way to visualize the correlation between the categorical variable `job_level` and continuous variable `wage`. Notice that there are a few outliers with large values, I manually adjust the y-axis to show the results.

```{r, echo=FALSE, fig.align="c", message=FALSE, warning=FALSE}
plotdata = data
plotdata$job_level = factor(plotdata$job_level)
ggplot(plotdata, aes(x = job_level, y = wage)) +
  geom_boxplot(colour = "black", fill = "#56B4E9") +
  scale_x_discrete(name = "Job Level") +
  scale_y_continuous(name = "Mean Wage", breaks = seq(10000, 210000, 20000), limits = c(10000, 200000)) +
  ggtitle("Boxplot of Mean Wage by Job Level") +
  theme(axis.line.x = element_line(size = 0.5, colour = "black"),
        axis.line.y = element_line(size = 0.5, colour = "black"),
        axis.line = element_line(size=1, colour = "black"),
        panel.grid.major = element_line(colour = "#d3d3d3"),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank())
```

Although it appears increasing trend when job level increases, when I manually check the dataset, I found the definition of "job level" is different in different companies. This means `job_level = 4` could be either the highest or lowest level in a company. Let's double check the wage distribution for each level.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# create histogram
df1 = data.frame(wage = data[data$job_level == 1,]$wage)
p1 = ggplot(df1, aes(x = wage)) + geom_histogram(bins = 50, fill = I("blue"), col = I("red"), alpha = I(.2)) + xlim(0, 150000) +
  ggtitle("Job Level = 1")

df2 = data.frame(wage = data[data$job_level == 2,]$wage)
p2 = ggplot(df2, aes(x = wage)) + geom_histogram(bins = 50, fill = I("blue"), col = I("red"), alpha = I(.2)) + xlim(0, 150000) +
  ggtitle("Job Level = 2")

df3 = data.frame(wage = data[data$job_level == 3,]$wage)
p3 = ggplot(df3, aes(x = wage)) + geom_histogram(bins = 50, fill = I("blue"), col = I("red"), alpha = I(.2)) + xlim(0, 150000) +
  ggtitle("Job Level = 3")

df4 = data.frame(wage = data[data$job_level == 4,]$wage)
p4 = ggplot(df4, aes(x = wage)) + geom_histogram(bins = 50, fill = I("blue"), col = I("red"), alpha = I(.2)) + xlim(0, 150000) +
  ggtitle("Job Level = 4")

multiplot(p1, p3, p2, p4, cols = 2)
```

There are some NAs in `job_level` as well. For simplicity, I will replace them using same strategy (LR).

```{r}
dataLM = data
job_levelLM = lm(job_level ~ wage + job_education, data = dataLM[!is.na(dataLM$job_level), ])
dataLM$job_level = round(predict(job_levelLM, dataLM), 0)

# if predicted value > 4, set as 4
dataLM$job_level = ifelse(dataLM$job_level > 4, 4, dataLM$job_level)

# Imputation
data[is.na(data$job_level), ]$job_level = dataLM$job_level[is.na(data$job_level)]
```

**8. `employee_citizenship`**

I don't expect to see any correlation between this variable and `wage`. But let's just do some simple visualization. Although I'm not showing the exact label, it's obvious that there is no pattern. What's more, some levels only have less than 5 entries, which reduces its predictability.

```{r, echo=FALSE, fig.align="c", message=FALSE, warning=FALSE}
plotdata = data
plotdata$employee_citizenship = factor(plotdata$employee_citizenship)
ggplot(plotdata, aes(x = employee_citizenship, y = wage)) +
  geom_boxplot(colour = "black", fill = "#56B4E9") +
  scale_x_discrete(name = "") +
  scale_y_continuous(name = "Mean Wage", breaks = seq(10000, 210000, 20000), limits = c(10000, 200000)) +
  ggtitle("Boxplot of Mean Wage by Citizenship") +
  theme(axis.line = element_line(size=1, colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.text.x=element_blank())
```

### Dataset After Cleaning
After imputation, let's check the dataset. There is only 1 missing value in `employer_yr_established`, however, previously it turns out to be irrelevant.

```{r}
sapply(data, function(x) {sum(is.na(x))})
```

## Feature Engineering
### Selection Based on EDA
From the analysis and plots above, I think only `employer_name`, `job_education`, `job_experience_num_month`, `job_state` and `job_level` would impact the `wage`. 

### Dummify the Data

```{r}
newdata = subset(data, select = c(job_education, 
                                  job_experience_num_months,
                                  job_state,
                                  employer_num_employees, 
                                  employer_yr_established,
                                  job_level, wage))
# Dummify the data
dmy = dummyVars(" ~ .", data = newdata, fullRank = T)
mydata = data.frame(predict(dmy, newdata = newdata))
```

### Gradient Boosting Trees for Feature Selection
Due to time limitation, I will randomly sample rows for original data set.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
set.seed(218)
gbm = train(wage ~ ., data = mydata[sample(nrow(mydata), 2000), ], 
            method = "gbm", 
            verbose = FALSE,
            na.action = na.pass)

head(summary(gbm), 8)
```

Combining the results of EDA and gbm model, I decide to keep `job_education`, `job_experience_num_months`, `job_level`, `employer_num_employees` and `job_state` as five most important predictors for building models in the following step.

## Model
### Cross-Validation
The k-fold cross validation method involves splitting the dataset into k-subsets. For each subset is held out while the model is trained on all other subsets. Here I set `k = 3` for simplicity.

```{r}
newdata = subset(data, select = c(job_education, 
                                  job_experience_num_months,
                                  job_state,
                                  employer_num_employees, 
                                  job_level, wage))
# # Dummify the data
# dmy = dummyVars(" ~ .", data = newdata, fullRank = T)
# mydata = data.frame(predict(dmy, newdata = newdata))

set.seed(218)
index = createDataPartition(newdata$wage, p = 0.7, list = FALSE)
train = mydata[index, ]
test = mydata[-index, ]

# Cross validation
cv_3 = trainControl(method = "cv", number = 3)
```

### Linear Regression Model

```{r, message=FALSE, warning=FALSE}
library(ModelMetrics)
lm = train(wage ~ ., data = train, 
           method = "lm", 
           trControl = cv_3,
           verbose = FALSE,
           na.action = na.pass)

# RMSE
lm_rmse = rmse(predict(lm, newdata = test), test$wage)
lm_rmse
```

### K-Nearest Neighbors

```{r}
# KNN
knn = train(wage ~ ., data = train, 
            method = "knn", 
            trControl = cv_3,
            verbose = FALSE,
            na.action = na.pass)

# RMSE
rmse(predict(svm, newdata = test), test$wage)
```



### Support Vector Machine (Linear Kernel)
I won't train this model with `cv_3` due to the limitation of time and memory.

```{r, message=FALSE, warning=FALSE}
# SVM with a linear kernel
svm = train(wage ~ ., data = train, 
           method = "svmLinear", 
           verbose = FALSE,
           na.action = na.pass)

# RMSE
rmse(predict(svm, newdata = test), test$wage)
```

### Neural Network
I won't train this model with `cv_3` due to the limitation of time and memory.

```{r}
# NN
nn = train(wage ~ ., data = train[1:10000, ], 
           method = "nnet", 
           verbose = FALSE,
           na.action = na.pass)

# RMSE
rmse(predict(nn, newdata = test), test$wage)
```




### Principal Component Analysis (Future work)
The principal components are supplied with normalized version of original predictors. This is because, the original predictors may have different scales.

**Drawback:** We may lose model interpretability.

## Model Building (Future work)
- K-Nearest Neighbors (KNN)
- Decision Tree
- Support Vector Machine (SVM) **Tried**
- Linear Regression **Tried**
- Multilayer Perceptron Neural Network (MIP)

**Linear Regression**
```{r, message=FALSE, warning=FALSE}
lm = train(wage ~ ., data = train, 
           method = "lm", 
           preProcess = "scale",
           trControl = cv_5,
           verbose = FALSE,
           na.action = na.pass)

# prediction
head(predict(lm, newdata = test))

# RMSE
rmse(predict(lm, newdata = test), test$wage)
```



```{r, message=FALSE, warning=FALSE}
# SVM with a linear kernel
svm = train(wage ~ ., data = train, 
           method = "svmLinear", 
           preProcess = "scale",
           trControl = cv_5,
           verbose = FALSE,
           na.action = na.pass)

# prediction
head(predict(svm, newdata = test))

# RMSE
rmse(predict(svm, newdata = test), test$wage)
```

### Evaluation

| Model  | RMSE |
|:----------:|:---------:|
| Linear Regression   |  155405.6   |
| Linear SVM |  153899.3   |
| Gradient Boosted Trees | 154377.5      |

Among all the models I tried, `Linear SVM` seems to perform the best because it has the least root mean squares error. However, there's not too much difference between those models, it's highly possible just due to random variation. Thus we can try a lot of other models including neural networks, which I don't have enough time to explore for this challenge.

I think this model will be somehow representative of the entire U.S. population because we're evaluating the model based on cross-validation results, which reduces the risk of overfitting.

## Future Work
If I were given more time, I could try
- K-Nearest Neighbors (KNN)
- Decision Tree
- Multilayer Perceptron Neural Network (MIP)

and other regression algorithms.

## Sidenotes
These are some of my analysis and thoughts of the dataset. I'm not sure if these make sense because of the limit of my background knowledge. But I'm a quick learner and more than willing to accept new knowledge. 

Please don’t hesitate to share any insights with me no matter you’d like to proceed my application or not, I would be really appreciated!
