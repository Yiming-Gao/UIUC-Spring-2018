---
title: "Text Mining on Yelp Reviews"
author: "Yiming Gao (yimingg2)"
date: "4/4/2018"
output: html_document
---

Some useful references:

- The Statistical Difference between 1-Star and 5-Star Reviews on Yelp: http://minimaxir.com/2014/09/one-star-five-stars/
- Analysis and Visualizations of Yelp Data using R and ggplot2: http://minimaxir.com/2015/12/lets-code-1/
- Sentiment Analysis of Restaurant Reviews: https://rpubs.com/yceron/155272 
- EDA (Filtering): https://rpubs.com/shreyaghelani/234363
- Mexicon restaurants: http://rstudio-pubs-static.s3.amazonaws.com/121639_3364a2eb69b54ed9b85faf1ecf21cd7f.html

The data set contains XX million reviews. It is formatted as by-line JSON: I wrote a pair of Python scripts to convert it to CSV for easy import into R.

The datasets are located here:

- Businesses Data: https://s3.us-east-2.amazonaws.com/578projectyelp/business.csv

Necessary packages:

```{r, message=FALSE, warning=FALSE}
library(stringr)        #This package is used for string manipulation functions
library(dplyr)          #This package is used for data manipulation tasks
library(tidyr)          #This package is used for data manipulation tasks
library(data.table)     #This package is used to access the function fread which is a better/faster way to read large data
library(wordcloud)      #This package is used to generate word clouds
library(tm)             #This is a text mining package used in the process of generating word clouds
# library(RWeka)          # This package is used to generate Bigramws and Trigrams
library(ggplot2)        #This package is used for visualizations (chart/graph plotting functions)
library(ggmap)          #This package is used for map functions 
library(maps)           #This package is used for map functions
library(leaflet)        #This package is used for plotting maps
library(knitr)
library(SnowballC)
```


### Read the data

```{r, message=FALSE, warning=FALSE}
data_business = fread("https://s3.us-east-2.amazonaws.com/578projectyelp/business.csv")

#Dimensions and attribute Names for the Business Data
dim(data_business)
```

### Clean up Reviews Data to filter Reviews for Champaign and Urbana only

```{r}
data_business$categories[1:5]
```

Becasue Categories column in Business Data Frame is a list that can have more than one category for the business, We parsed the categories column and built another data frame that contains information for all "Restaurants". We executed this one time and stored the result in a CSV file.

Now the dataset contains 21892 observations with "Restaurants" in the `categories` column.

```{r}
data_business_restaurants = data_business[data_business$categories %like% "Restaurants", ]
dim(data_business_restaurants)

# Keep relevant columns
data_business_restaurants = data_business_restaurants[, c("business_id", "city", "latitude", "longitude", "name", "stars", "state")]
```

The Reviews Data file was read and filtered for restaurant reviews and further filtered for two cities - Champaign and Urbana. This was done in order to be able to work with a smaller data-set for the scope of this project. Since the original Reviews data is 1.1GB (1569264 rows and 10 columns). The following piece of code was used to get to the reviews dataset for restaurants in Urbana-Champaign from the original reviews dataset.

```{r, message=FALSE, warning=FALSE}
data_business_restaurants = fread("https://s3.us-east-2.amazonaws.com/578projectyelp/business_restaurants.csv")

data_review0 = fread("https://s3.us-east-2.amazonaws.com/578projectyelp/review.csv")

# Dimensions and attribute Names for the Business Data
dim(data_review0)

# Keep relevant columns
data_review = data_review0[, c("business_id", "stars", "text", "votes_cool", "votes_funny", "votes_useful")]
```


```{r, message=FALSE, warning=FALSE}
# Business_id of Restaurants in Chambana
chambana_restaurants = data_business_restaurants %>% 
  filter(city == "Champaign" | city == "Urbana") %>%
  select(business_id, name, stars, latitude, longitude)

# Reviews Data only for Restaurants in Chambana
chambana_reviews = fread("https://s3.us-east-2.amazonaws.com/578projectyelp/chambana_reviews.csv")
```

```{r}
# Final review dataset
dim(chambana_reviews)
names(chambana_reviews)
```


### Preparing the data
```{r}
chambana_restaurants = 
chambana_reviews = fread("https://s3.us-east-2.amazonaws.com/578projectyelp/chambana_reviews.csv")
```

For simplicity, only the attributes that are relevant to my project will be listed. It includes the following information:

| Field        |  Description                                                |
|:------------:|:-----------------------------------------------------------:|
| business_id  | The unique identifier for the business                      |
| name         | The full business name                                      |
| categories   | Category this business belongs to

Table: Business Dataset 




# EDA
### Where are all the restaurants with more than 4 stars located?

```{r}
top_restaurants = chambana_restaurants[chambana_restaurants$stars >= 4, ]
leaflet(top_restaurants) %>% addTiles() %>%
  addCircleMarkers(lng = ~longitude, lat = ~latitude, radius = 5, fillOpacity = 1 , color = "orange" , popup = ~name) 
```

# Text Mining
## Wordcloud
### Wordcloud
In this section, we use R packages for text mining of actual texts of Reviews related to Chambana restaurants to find what are the top frequent words used in reviews with different review ratings. We also do similar analysis to find what are frequent words used in reviews related to business ratings and find whether we can find a correlation between these two findings.

The code in below shows the technique we used to find 100 frequent words related to Chambana restaurants with review ratings 4 or 5. (OR 1 &2)

```{r}
data = chambana_reviews[chambana_reviews$stars == 4 | chambana_reviews$stars == 5, ]
text = as.vector(data$text)
corpus = VCorpus(VectorSource(text))
corpus = tm_map(corpus, content_transformer(tolower)) # change all letters to lowercase
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, stripWhitespace)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, removeWords, stopwords("SMART"))
corpus = tm_map(corpus, stemDocument) # text stemming

# Build a term-document matrix
dtm = TermDocumentMatrix(corpus)
m = as.matrix(dtm)
v = sort(rowSums(m), decreasing = TRUE)
d = data.frame(word = names(v), freq = v)
head(d, 10)
```

```{r, message=FALSE, warning=FALSE}
# Wordcloud
set.seed(122)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words = 200, random.order = FALSE, rot.per = 0.35, 
          colors = brewer.pal(8, "Dark2"))
```

The above word cloud clearly shows that "place", "good", "food" and "great" are most frequent words in the reviews of restaurants with 4 or 5 stars in Champaign-Urbana.

### Explore frequent terms and their associations
We can have a look at the frequent terms in the term-document matrix as follows. Below shows the words that occur at least 500 times.

```{r}
findFreqTerms(dtm, lowfreq = 500)
```

We can analyze the association between frequent terms (i.e., terms which correlate). The code below identifies which words are associated with "food" in reviews in Chambana restaurants.

```{r}
findAssocs(dtm, terms = "burger", corlimit = 0.3)
```

The frequency of the first 10 frequent words are plotted:

```{r}
barplot(d[1:10, ]$freq, las = 2, names.arg = d[1:10,]$word,
        col = "lightblue", main = "Most Frequent Words",
        ylab = "Word frequencies")
```

# Model
## A Tokenization Model to predict rating based on words in review
